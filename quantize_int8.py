"""
Kokoro ONNX æ¨¡å‹ INT8 é‡åŒ–

å°† ~310MB çš„æ¨¡å‹å‹ç¼©åˆ° ~80MB
é€Ÿåº¦æå‡ 2-4xï¼Œè´¨é‡æŸå¤±æœ€å°
"""

from onnxruntime.quantization import quantize_dynamic, QuantType
import argparse
import os


def quantize_model_int8(input_model, output_model=None):
    """
    INT8 åŠ¨æ€é‡åŒ–
    
    Args:
        input_model: è¾“å…¥ ONNX æ¨¡å‹è·¯å¾„
        output_model: è¾“å‡ºé‡åŒ–æ¨¡å‹è·¯å¾„
    """
    if output_model is None:
        base, ext = os.path.splitext(input_model)
        output_model = f"{base}_int8{ext}"
    
    print("=" * 70)
    print("Kokoro ONNX INT8 é‡åŒ–")
    print("=" * 70)
    
    input_size = os.path.getsize(input_model) / (1024 * 1024)
    print(f"\nğŸ“Š è¾“å…¥æ¨¡å‹:")
    print(f"   æ–‡ä»¶: {input_model}")
    print(f"   å¤§å°: {input_size:.2f} MB")
    
    print(f"\nâš™ï¸  å¼€å§‹é‡åŒ–...")
    print(f"   ç±»å‹: INT8 åŠ¨æ€é‡åŒ–")
    print(f"   è¿™ä¼šå‹ç¼©æƒé‡åˆ° int8ï¼Œæ¨ç†æ—¶åŠ¨æ€è½¬æ¢")
    
    try:
        quantize_dynamic(
            model_input=input_model,
            model_output=output_model,
            weight_type=QuantType.QInt8
            # å¯ä»¥æŒ‡å®šè¦æ’é™¤çš„æ“ä½œç±»å‹
            # op_types_to_quantize=['Conv', 'MatMul']
        )
        
        output_size = os.path.getsize(output_model) / (1024 * 1024)
        compression_ratio = (1 - output_size / input_size) * 100
        
        print(f"\nâœ… é‡åŒ–æˆåŠŸ!")
        print(f"\nğŸ“Š è¾“å‡ºæ¨¡å‹:")
        print(f"   æ–‡ä»¶: {os.path.abspath(output_model)}")
        print(f"   å¤§å°: {output_size:.2f} MB")
        print(f"   å‹ç¼©: {compression_ratio:.1f}% (ä» {input_size:.2f} MB åˆ° {output_size:.2f} MB)")
        
        print(f"\nğŸ’¡ æ€§èƒ½é¢„æœŸ:")
        print(f"   - å¤§å°: ~{compression_ratio:.0f}% å‡å°‘")
        print(f"   - é€Ÿåº¦: 2-4x æå‡ (å–å†³äºç¡¬ä»¶)")
        print(f"   - è´¨é‡: å¯¹ Kokoro å½±å“å¾ˆå°")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ é‡åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(description='é‡åŒ– Kokoro ONNX æ¨¡å‹åˆ° INT8')
    parser.add_argument(
        'input',
        nargs='?',
        default='kokoro_latest.onnx',
        help='è¾“å…¥ ONNX æ¨¡å‹è·¯å¾„'
    )
    parser.add_argument(
        '--output',
        help='è¾“å‡ºé‡åŒ–æ¨¡å‹è·¯å¾„ (é»˜è®¤: è¾“å…¥æ–‡ä»¶å_int8.onnx)'
    )
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print(f"   python quantize_int8.py [è¾“å…¥æ¨¡å‹.onnx]")
        return
    
    success = quantize_model_int8(args.input, args.output)
    
    if success:
        print("\n" + "=" * 70)
        print("ğŸ‰ å®Œæˆ!")
        print("=" * 70)
        print(f"\nğŸ“ ä¸‹ä¸€æ­¥:")
        print(f"  æµ‹è¯•é‡åŒ–æ¨¡å‹: python test_onnx_inference.py {args.output or args.input.replace('.onnx', '_int8.onnx')}")


if __name__ == "__main__":
    main()
