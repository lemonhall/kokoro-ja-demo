/**
 * test_tokenizer_zh.c
 * 
 * æµ‹è¯•ä¸­æ–‡åˆ†è¯å™¨
 * 
 * License: MIT
 */

#include "misaki_tokenizer.h"
#include "misaki_trie.h"
#include <stdio.h>
#include <string.h>
#include <assert.h>

// æµ‹è¯•ç»“æœç»Ÿè®¡
static int test_passed = 0;
static int test_failed = 0;

#define TEST_ASSERT(cond, msg) do { \
    if (!(cond)) { \
        printf("  âŒ FAIL: %s\n", msg); \
        test_failed++; \
        return; \
    } \
} while(0)

#define RUN_TEST(test_func) do { \
    printf("\nğŸ§ª Running %s...\n", #test_func); \
    test_func(); \
    test_passed++; \
} while(0)

/* ============================================================================
 * ä¸­æ–‡åˆ†è¯å™¨æµ‹è¯•
 * ========================================================================== */

void test_zh_tokenizer_create() {
    Trie *trie = misaki_trie_create();
    TEST_ASSERT(trie != NULL, "Trie åº”è¯¥åˆ›å»ºæˆåŠŸ");
    
    // æ·»åŠ æµ‹è¯•è¯æ±‡
    misaki_trie_insert(trie, "ä½ å¥½", 1000.0, NULL);
    misaki_trie_insert(trie, "ä¸–ç•Œ", 800.0, NULL);
    
    ZhTokenizerConfig config = {
        .dict_trie = trie,
        .enable_hmm = false,
        .enable_userdict = false,
        .user_trie = NULL
    };
    
    void *tokenizer = misaki_zh_tokenizer_create(&config);
    TEST_ASSERT(tokenizer != NULL, "ä¸­æ–‡åˆ†è¯å™¨åº”è¯¥åˆ›å»ºæˆåŠŸ");
    
    misaki_zh_tokenizer_free(tokenizer);
    misaki_trie_free(trie);
    
    printf("  âœ… ä¸­æ–‡åˆ†è¯å™¨åˆ›å»ºæˆåŠŸ\n");
}

void test_zh_tokenize_simple() {
    // åˆ›å»ºè¯å…¸
    Trie *trie = misaki_trie_create();
    misaki_trie_insert(trie, "ä½ å¥½", 1000.0, NULL);
    misaki_trie_insert(trie, "ä¸–ç•Œ", 800.0, NULL);
    
    ZhTokenizerConfig config = {
        .dict_trie = trie,
        .enable_hmm = false,
        .enable_userdict = false,
        .user_trie = NULL
    };
    
    void *tokenizer = misaki_zh_tokenizer_create(&config);
    
    // æµ‹è¯•åˆ†è¯
    const char *text = "ä½ å¥½ä¸–ç•Œ";
    MisakiTokenList *tokens = misaki_zh_tokenize(tokenizer, text);
    TEST_ASSERT(tokens != NULL, "åˆ†è¯ç»“æœä¸åº”ä¸º NULL");
    
    int count = misaki_token_list_size(tokens);
    printf("  åˆ†è¯ç»“æœ: %d ä¸ªè¯\n", count);
    
    for (int i = 0; i < count; i++) {
        MisakiToken *token = misaki_token_list_get(tokens, i);
        printf("    [%d] %s\n", i, token->text);
    }
    
    TEST_ASSERT(count == 2, "åº”è¯¥åˆ†æˆ 2 ä¸ªè¯");
    
    MisakiToken *token0 = misaki_token_list_get(tokens, 0);
    TEST_ASSERT(strcmp(token0->text, "ä½ å¥½") == 0, "ç¬¬ä¸€ä¸ªè¯åº”è¯¥æ˜¯'ä½ å¥½'");
    
    MisakiToken *token1 = misaki_token_list_get(tokens, 1);
    TEST_ASSERT(strcmp(token1->text, "ä¸–ç•Œ") == 0, "ç¬¬äºŒä¸ªè¯åº”è¯¥æ˜¯'ä¸–ç•Œ'");
    
    misaki_token_list_free(tokens);
    misaki_zh_tokenizer_free(tokenizer);
    misaki_trie_free(trie);
    
    printf("  âœ… ä¸­æ–‡åˆ†è¯æµ‹è¯•é€šè¿‡\n");
}

void test_zh_tokenize_with_real_dict() {
    // ä»çœŸå®è¯å…¸æ–‡ä»¶åŠ è½½
    const char *dict_path = "../extracted_data/zh/dict.txt";
    Trie *trie = misaki_trie_create();
    
    int word_count = misaki_trie_load_from_file(trie, dict_path, "word freq");
    if (word_count < 0) {
        printf("  âš ï¸  æ— æ³•åŠ è½½è¯å…¸æ–‡ä»¶ï¼Œè·³è¿‡æµ‹è¯•\n");
        misaki_trie_free(trie);
        return;
    }
    
    printf("  åŠ è½½äº† %d ä¸ªè¯æ±‡\n", word_count);
    
    ZhTokenizerConfig config = {
        .dict_trie = trie,
        .enable_hmm = false,
        .enable_userdict = false,
        .user_trie = NULL
    };
    
    void *tokenizer = misaki_zh_tokenizer_create(&config);
    
    // æµ‹è¯•å¤šä¸ªå¥å­
    const char *texts[] = {
        "ä¸­å›½",
        "æˆ‘ä»¬",
        "ç»æµå‘å±•",
        NULL
    };
    
    for (int i = 0; texts[i] != NULL; i++) {
        MisakiTokenList *tokens = misaki_zh_tokenize(tokenizer, texts[i]);
        if (tokens) {
            printf("  \"%s\" â†’", texts[i]);
            for (int j = 0; j < tokens->count; j++) {
                printf(" [%s]", tokens->tokens[j].text);
            }
            printf("\n");
            misaki_token_list_free(tokens);
        }
    }
    
    misaki_zh_tokenizer_free(tokenizer);
    misaki_trie_free(trie);
    
    printf("  âœ… çœŸå®è¯å…¸åˆ†è¯æµ‹è¯•é€šè¿‡\n");
}

/* ============================================================================
 * ä¸»æµ‹è¯•å‡½æ•°
 * ========================================================================== */

int main(void) {
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    printf("  ä¸­æ–‡åˆ†è¯å™¨æµ‹è¯•\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    
    RUN_TEST(test_zh_tokenizer_create);
    RUN_TEST(test_zh_tokenize_simple);
    RUN_TEST(test_zh_tokenize_with_real_dict);
    
    // æ€»ç»“
    printf("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    printf("  æµ‹è¯•ç»“æœ:\n");
    printf("  âœ… é€šè¿‡: %d\n", test_passed);
    printf("  âŒ å¤±è´¥: %d\n", test_failed);
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    
    return test_failed > 0 ? 1 : 0;
}
