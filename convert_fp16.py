"""
Kokoro ONNX æ¨¡å‹ FP16 è½¬æ¢

å°† ~310MB çš„æ¨¡å‹å‹ç¼©åˆ° ~155MB
åœ¨æ”¯æŒ FP16 çš„ç¡¬ä»¶ä¸Šé€Ÿåº¦æ›´å¿«
"""

from onnxconverter_common import float16
import onnx
import argparse
import os


def convert_model_fp16(input_model, output_model=None):
    """
    FP16 è½¬æ¢
    
    Args:
        input_model: è¾“å…¥ ONNX æ¨¡å‹è·¯å¾„
        output_model: è¾“å‡º FP16 æ¨¡å‹è·¯å¾„
    """
    if output_model is None:
        base, ext = os.path.splitext(input_model)
        output_model = f"{base}_fp16{ext}"
    
    print("=" * 70)
    print("Kokoro ONNX FP16 è½¬æ¢")
    print("=" * 70)
    
    input_size = os.path.getsize(input_model) / (1024 * 1024)
    print(f"\nğŸ“Š è¾“å…¥æ¨¡å‹:")
    print(f"   æ–‡ä»¶: {input_model}")
    print(f"   å¤§å°: {input_size:.2f} MB")
    
    print(f"\nâš™ï¸  å¼€å§‹è½¬æ¢...")
    print(f"   ç±»å‹: FP32 -> FP16")
    print(f"   è¿™ä¼šå°†æ‰€æœ‰æƒé‡ä» 32ä½ è½¬æ¢ä¸º 16ä½æµ®ç‚¹æ•°")
    
    try:
        # åŠ è½½æ¨¡å‹
        model = onnx.load(input_model)
        
        # è½¬æ¢ä¸º FP16
        model_fp16 = float16.convert_float_to_float16(model)
        
        # ä¿å­˜
        onnx.save(model_fp16, output_model)
        
        output_size = os.path.getsize(output_model) / (1024 * 1024)
        compression_ratio = (1 - output_size / input_size) * 100
        
        print(f"\nâœ… è½¬æ¢æˆåŠŸ!")
        print(f"\nğŸ“Š è¾“å‡ºæ¨¡å‹:")
        print(f"   æ–‡ä»¶: {os.path.abspath(output_model)}")
        print(f"   å¤§å°: {output_size:.2f} MB")
        print(f"   å‹ç¼©: {compression_ratio:.1f}% (ä» {input_size:.2f} MB åˆ° {output_size:.2f} MB)")
        
        print(f"\nğŸ’¡ æ€§èƒ½é¢„æœŸ:")
        print(f"   - å¤§å°: ~50% å‡å°‘")
        print(f"   - é€Ÿåº¦: åœ¨æ”¯æŒ FP16 çš„ GPU/NPU ä¸Šæ›´å¿«")
        print(f"   - è´¨é‡: é€šå¸¸å½±å“å¾ˆå°")
        print(f"\nâš ï¸  æ³¨æ„:")
        print(f"   - CPU ä¸Šå¯èƒ½æ²¡æœ‰åŠ é€Ÿæ•ˆæœ")
        print(f"   - GPU/NPU (å¦‚ ARM Mali, Adreno) ä¼šæœ‰æ˜æ˜¾åŠ é€Ÿ")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(description='è½¬æ¢ Kokoro ONNX æ¨¡å‹åˆ° FP16')
    parser.add_argument(
        'input',
        nargs='?',
        default='kokoro_latest.onnx',
        help='è¾“å…¥ ONNX æ¨¡å‹è·¯å¾„'
    )
    parser.add_argument(
        '--output',
        help='è¾“å‡º FP16 æ¨¡å‹è·¯å¾„ (é»˜è®¤: è¾“å…¥æ–‡ä»¶å_fp16.onnx)'
    )
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print(f"   python convert_fp16.py [è¾“å…¥æ¨¡å‹.onnx]")
        return
    
    success = convert_model_fp16(args.input, args.output)
    
    if success:
        print("\n" + "=" * 70)
        print("ğŸ‰ å®Œæˆ!")
        print("=" * 70)
        print(f"\nğŸ“ ä¸‹ä¸€æ­¥:")
        print(f"  æµ‹è¯• FP16 æ¨¡å‹: python test_onnx_inference.py {args.output or args.input.replace('.onnx', '_fp16.onnx')}")


if __name__ == "__main__":
    try:
        import onnxconverter_common
    except ImportError:
        print("âŒ ç¼ºå°‘ä¾èµ–ï¼Œè¯·å…ˆå®‰è£…:")
        print("   uv add onnxconverter-common")
        exit(1)
    
    main()
