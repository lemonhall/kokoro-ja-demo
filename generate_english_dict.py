#!/usr/bin/env python3
"""
ç”Ÿæˆè‹±æ–‡å‘éŸ³å­—å…¸

ä½¿ç”¨å®Œæ•´çš„ CMU Pronouncing Dictionary (CMUdict)
åŒ…å« 13 ä¸‡+ è‹±æ–‡å•è¯çš„å‘éŸ³æ•°æ®
"""

import json
import re
import pronouncing

def arpabet_to_ipa(arpabet):
    """
    å°† ARPAbet éŸ³ç´ è½¬æ¢ä¸º IPA
    
    ARPAbet æ˜¯ CMUdict ä½¿ç”¨çš„éŸ³æ ‡ç³»ç»Ÿ
    """
    # ARPAbet â†’ IPA æ˜ å°„è¡¨
    mapping = {
        # å…ƒéŸ³
        'AA': 'É‘', 'AE': 'Ã¦', 'AH': 'ÊŒ', 'AO': 'É”', 'AW': 'aÊŠ',
        'AX': 'É™', 'AXR': 'Éš', 'AY': 'aÉª', 'EH': 'É›', 'ER': 'É',
        'EY': 'eÉª', 'IH': 'Éª', 'IX': 'É¨', 'IY': 'i', 'OW': 'oÊŠ',
        'OY': 'É”Éª', 'UH': 'ÊŠ', 'UW': 'u', 'UX': 'Ê‰',
        
        # è¾…éŸ³
        'B': 'b', 'CH': 'Ê§', 'D': 'd', 'DH': 'Ã°', 'DX': 'É¾',
        'EL': 'lÌ©', 'EM': 'mÌ©', 'EN': 'nÌ©', 'F': 'f', 'G': 'É¡',
        'HH': 'h', 'JH': 'Ê¤', 'K': 'k', 'L': 'l', 'M': 'm',
        'N': 'n', 'NG': 'Å‹', 'NX': 'É¾Ìƒ', 'P': 'p', 'Q': 'Ê”',
        'R': 'r', 'S': 's', 'SH': 'Êƒ', 'T': 't', 'TH': 'Î¸',
        'V': 'v', 'W': 'w', 'WH': 'Ê', 'Y': 'j', 'Z': 'z',
        'ZH': 'Ê’'
    }
    
    # ç§»é™¤é‡éŸ³æ ‡è®° (0, 1, 2)
    phoneme = re.sub(r'[012]', '', arpabet)
    
    return mapping.get(phoneme, phoneme.lower())


def generate_full_cmudict():
    """
    ç”Ÿæˆå®Œæ•´çš„ CMUdict å‘éŸ³å­—å…¸
    
    ä½¿ç”¨ pronouncing åº“åŠ è½½å®Œæ•´çš„ CMU å‘éŸ³è¯å…¸
    åŒ…å« 13 ä¸‡+ å•è¯
    """
    
    print("ğŸ“š åŠ è½½ CMU Pronouncing Dictionary...")
    
    # è·å– CMUdict çš„æ‰€æœ‰è¯æ¡
    from pronouncing import cmudict
    
    pronunciation_dict = {}
    total_words = 0
    processed_words = 0
    
    # CMUdict åŸå§‹æ•°æ®
    for word, pronunciations in cmudict.dict().items():
        total_words += 1
        
        # åªå–ç¬¬ä¸€ä¸ªå‘éŸ³ï¼ˆå¤šéŸ³å­—é—®é¢˜ï¼‰
        if pronunciations:
            arpabet_list = pronunciations[0]  # å¦‚ ['AY1', 'F', 'OW1', 'N']
            
            # è½¬æ¢ä¸º IPA
            ipa_phonemes = [arpabet_to_ipa(p) for p in arpabet_list]
            pronunciation_dict[word.lower()] = " ".join(ipa_phonemes)
            
            processed_words += 1
        
        # è¿›åº¦æç¤º
        if total_words % 10000 == 0:
            print(f"   å·²å¤„ç†: {total_words} ä¸ªå•è¯...")
    
    print(f"\nâœ… å­—å…¸ç”Ÿæˆå®Œæˆï¼")
    print(f"   æ€»è¯æ¡: {total_words}")
    print(f"   æœ‰æ•ˆè¯æ¡: {processed_words}")
    
    return pronunciation_dict


def main():
    """ä¸»å‡½æ•°"""
    
    print("=" * 60)
    print("ç”Ÿæˆè‹±æ–‡å‘éŸ³å­—å…¸")
    print("=" * 60)
    print()
    
    # ç”Ÿæˆå­—å…¸
    pronunciation_dict = generate_full_cmudict()
    
    print(f"âœ… å­—å…¸ç”Ÿæˆå®Œæˆï¼")
    print(f"   åŒ…å« {len(pronunciation_dict)} ä¸ªå•è¯")
    
    # ä¿å­˜ä¸º JSON
    output_file = "app/src/main/assets/english_dict.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(pronunciation_dict, f, ensure_ascii=False, indent=2)
    
    file_size = len(json.dumps(pronunciation_dict, ensure_ascii=False)) / 1024
    
    print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°: {output_file}")
    print(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} KB")
    
    # æµ‹è¯•æ ·ä¾‹
    print(f"\nğŸ” æµ‹è¯•æ ·ä¾‹:")
    test_words = ["iphone", "hello", "world", "test", "one", "a"]
    for word in test_words:
        ipa = pronunciation_dict.get(word, "???")
        print(f"   {word} â†’ {ipa}")
    
    print("\nâœ… å®Œæˆï¼")
    print("\nğŸ“ ä¸‹ä¸€æ­¥:")
    print("   1. Kotlin ä»£ç åŠ è½½ english_dict.json")
    print("   2. å®ç° EnglishG2PSystem")
    print("   3. é›†æˆåˆ° UnifiedG2PSystem")
    print()


if __name__ == "__main__":
    main()
