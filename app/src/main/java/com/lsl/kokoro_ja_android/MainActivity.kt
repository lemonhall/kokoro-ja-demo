package com.lsl.kokoro_ja_android

import android.media.AudioAttributes
import android.media.AudioFormat
import android.media.AudioTrack
import android.os.Bundle
import android.widget.ArrayAdapter
import android.widget.Button
import android.widget.EditText
import android.widget.Spinner
import android.widget.TextView
import androidx.appcompat.app.AppCompatActivity
import androidx.lifecycle.lifecycleScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext

class MainActivity : AppCompatActivity() {
    
    private val engine = KokoroEngine(this)
    private lateinit var g2pSystem: UnifiedG2PSystem  // ç»Ÿä¸€ G2P ç³»ç»Ÿï¼ˆæ”¯æŒè‡ªåŠ¨è¯­è¨€æ£€æµ‹ï¼‰
    private var audioTrack: AudioTrack? = null
    private var currentSentenceIndex = 0
    
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)
        
        val statusText = findViewById<TextView>(R.id.statusText)
        val sentenceSpinner = findViewById<Spinner>(R.id.sentenceSpinner)
        val customTextInput = findViewById<EditText>(R.id.customTextInput)
        val synthesizeButton = findViewById<Button>(R.id.synthesizeButton)
        
        // è®¾ç½®æ—¥æ–‡å¥å­é€‰æ‹©å™¨
        val adapter = ArrayAdapter(
            this,
            android.R.layout.simple_spinner_item,
            JapanesePresets.getTextList()
        )
        adapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item)
        sentenceSpinner.adapter = adapter
        
        // åˆå§‹åŒ–æ¨¡å‹
        lifecycleScope.launch {
            try {
                statusText.text = "æ­£åœ¨åŠ è½½æ¨¡å‹...\nè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ"
                
                // å¹¶è¡Œåˆå§‹åŒ– TTS å¼•æ“å’Œç»Ÿä¸€ G2P ç³»ç»Ÿ
                engine.initialize("kokoro_fp32.onnx")
                g2pSystem = withContext(Dispatchers.Default) {
                    UnifiedG2PSystem(this@MainActivity)  // è‡ªåŠ¨æ”¯æŒä¸­æ—¥éŸ©å¤šè¯­è¨€
                }
                
                statusText.text = "âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\n\n" +
                        "âœ… æ™ºèƒ½å¤šè¯­è¨€æ”¯æŒï¼\n" +
                        "ğŸ‡¨ğŸ‡³ ä¸­æ–‡ï¼šä½ å¥½ä¸–ç•Œ\n" +
                        "ğŸ‡¯ğŸ‡µ æ—¥æ–‡ï¼šã“ã‚“ã«ã¡ã¯\n" +
                        "ğŸ‡°ğŸ‡· éŸ©æ–‡ï¼šæ•¬è¯·æœŸå¾…\n\n" +
                        "æ— éœ€åˆ‡æ¢ï¼Œè‡ªåŠ¨è¯†åˆ«è¯­è¨€ï¼"
                synthesizeButton.isEnabled = true
            } catch (e: Exception) {
                statusText.text = "âŒ æ¨¡å‹åŠ è½½å¤±è´¥:\n${e.message}"
                e.printStackTrace()
            }
        }
        
        // åˆæˆæŒ‰é’®
        synthesizeButton.setOnClickListener {
            lifecycleScope.launch {
                val customText = customTextInput.text.toString().trim()
                if (customText.isNotEmpty()) {
                    // ä½¿ç”¨è‡ªå®šä¹‰æ–‡æœ¬
                    synthesizeCustomText(customText, statusText)
                } else {
                    // ä½¿ç”¨é¢„è®¾å¥å­
                    currentSentenceIndex = sentenceSpinner.selectedItemPosition
                    synthesizeSentence(currentSentenceIndex, statusText)
                }
            }
        }
    }
    
    private suspend fun synthesizeCustomText(text: String, statusText: TextView) {
        try {
            // 1ï¸âƒ£ æ£€æµ‹è¯­è¨€
            val langInfo = withContext(Dispatchers.Default) {
                g2pSystem.getDetectedLanguageInfo(text)
            }
            
            statusText.text = "æ­£åœ¨åˆ†æ...\n" +
                    "è¾“å…¥: $text\n" +
                    "è¯­è¨€: ${langInfo.languageName} (è‡ªåŠ¨æ£€æµ‹)"
            
            // 2ï¸âƒ£ è½¬æ¢ä¸ºéŸ³ç´ ï¼ˆè‡ªåŠ¨é€‰æ‹© G2P å¼•æ“ï¼‰
            val phonemes = withContext(Dispatchers.Default) {
                g2pSystem.textToPhonemes(text)
            }
            
            // ğŸ“Š è°ƒè¯•æ—¥å¿—
            println("G2P_AUTO_DETECT: $text -> [${langInfo.languageCode}] -> $phonemes")
            
            // 3ï¸âƒ£ è·å–è½¬æ¢è¯¦æƒ…
            val conversionDetails = withContext(Dispatchers.Default) {
                g2pSystem.getConversionDetails(text)
            }
            
            statusText.text = "æ­£åœ¨åˆæˆ...\n" +
                    "åŸæ–‡: $text\n" +
                    "è¯­è¨€: ${langInfo.languageName}\n" +
                    "éŸ³ç´ : $phonemes\n" +
                    "éŸ³è‰²: ${langInfo.recommendedVoice}"
            
            // è®¡æ—¶å¼€å§‹
            val startTime = System.currentTimeMillis()
            
            // è½¬æ¢éŸ³ç´ ä¸º input_ids
            val inputIds = KokoroVocabFull.phonemesToIds(phonemes)
            
            // æ ¹æ®è¯­è¨€è‡ªåŠ¨åŠ è½½å¯¹åº”çš„è¯­éŸ³åµŒå…¥
            val voiceEmbedding = VoiceEmbeddingLoader.load(this, langInfo.recommendedVoice)
            
            val preprocessTime = System.currentTimeMillis() - startTime
            
            // æ¨ç†
            val inferenceStart = System.currentTimeMillis()
            val waveform = engine.synthesize(inputIds, voiceEmbedding, speed = 1.0)
            val inferenceTime = System.currentTimeMillis() - inferenceStart
            
            // è°ƒè¯•ä¿¡æ¯
            val maxVal = waveform.maxOrNull() ?: 0f
            val minVal = waveform.minOrNull() ?: 0f
            val totalTime = System.currentTimeMillis() - startTime
            val audioDuration = waveform.size / 24000.0
            val rtf = totalTime / 1000.0 / audioDuration
            
            println("ğŸµ éŸ³é¢‘ç”Ÿæˆ: é•¿åº¦=${waveform.size}, æœ€å¤§å€¼=$maxVal, æœ€å°å€¤=$minVal")
            println("â±ï¸ æ€§èƒ½: é¢„å¤„ç†=${preprocessTime}ms, æ¨ç†=${inferenceTime}ms, æ€»è€—æ—¶=${totalTime}ms, RTF=${String.format("%.2f", rtf)}")
            
            statusText.text = "âœ… åˆæˆæˆåŠŸ!\n" +
                    "åŸæ–‡: $text\n" +
                    "è¯­è¨€: ${langInfo.languageName}\n" +
                    "éŸ³è‰²: ${langInfo.recommendedVoice}\n" +
                    "éŸ³é¢‘: ${String.format("%.2f", audioDuration)}ç§’\n" +
                    "âš™ï¸ æ€§èƒ½: æ¨ç† ${inferenceTime}ms (RTF ${String.format("%.2fx", rtf)})\n" +
                    "æ­£åœ¨æ’­æ”¾..."
            
            playAudio(waveform)
            
            statusText.text = "âœ… æ’­æ”¾å®Œæˆ!\n" +
                    "åŸæ–‡: $text\n" +
                    "è¯­è¨€: ${langInfo.languageName}\n" +
                    "å¯ä»¥ç»§ç»­è¾“å…¥å…¶ä»–è¯­è¨€æ–‡æœ¬ï¼"
            
        } catch (e: Exception) {
            statusText.text = "âŒ åˆæˆå¤±è´¥:\n${e.message}"
            e.printStackTrace()
        }
    }

    private suspend fun synthesizeSentence(index: Int, statusText: TextView) {
        try {
            val sentence = JapanesePresets.sentences[index]
            
            statusText.text = "æ­£åœ¨åˆæˆ...\n" +
                    "æ—¥æ–‡: ${sentence.text}\n" +
                    "æ„æ€: ${sentence.translation}\n" +
                    "éŸ³ç´ : ${sentence.phonemes}"
            
            // è®¡æ—¶å¼€å§‹
            val startTime = System.currentTimeMillis()
            
            // è½¬æ¢éŸ³ç´ ä¸º input_ids
            val inputIds = KokoroVocabFull.phonemesToIds(sentence.phonemes)
            
            // åŠ è½½çœŸå®çš„è¯­éŸ³åµŒå…¥
            val voiceEmbedding = VoiceEmbeddingLoader.load(this, "jf_nezumi")
            
            val preprocessTime = System.currentTimeMillis() - startTime
            
            // æ¨ç†ï¼ˆå°è¯•ä¸åŒçš„è¯­é€Ÿä»¥æ”¹å–„éŸ³è‰²ï¼‰
            val inferenceStart = System.currentTimeMillis()
            val waveform = engine.synthesize(inputIds, voiceEmbedding, speed = 1.0)
            val inferenceTime = System.currentTimeMillis() - inferenceStart
            
            // è°ƒè¯•ä¿¡æ¯
            val maxVal = waveform.maxOrNull() ?: 0f
            val minVal = waveform.minOrNull() ?: 0f
            val totalTime = System.currentTimeMillis() - startTime
            val audioDuration = waveform.size / 24000.0
            val rtf = totalTime / 1000.0 / audioDuration  // Real-Time Factor
            
            println("ğŸµ éŸ³é¢‘ç”Ÿæˆ: é•·åº¦=${waveform.size}, æœ€å¤§å€¤=$maxVal, æœ€å°å€¤=$minVal")
            println("â±ï¸ æ€§èƒ½: é¢„å¤„ç†=${preprocessTime}ms, æ¨ç†=${inferenceTime}ms, æ€»è€—æ—¶=${totalTime}ms, RTF=${String.format("%.2f", rtf)}")
            
            statusText.text = "âœ… åˆæˆæˆåŠŸ!\n" +
                    "æ—¥æ–‡: ${sentence.text}\n" +
                    "æ„æ€: ${sentence.translation}\n" +
                    "éŸ³é¢‘: ${String.format("%.2f", audioDuration)}ç§’\n" +
                    "éŸ³é‡: [$minVal, $maxVal]\n" +
                    "âš™ï¸ æ€§èƒ½:\n" +
                    "  é¢„å¤„ç†: ${preprocessTime}ms\n" +
                    "  æ¨ç†: ${inferenceTime}ms\n" +
                    "  æ€»è€—æ—¶: ${totalTime}ms\n" +
                    "  RTF: ${String.format("%.2fx", rtf)}\n" +
                    "æ­£åœ¨æ’­æ”¾..."
            
            // æ’­æ”¾éŸ³é¢‘
            playAudio(waveform)
            
            // æ’­æ”¾å®Œæˆ
            statusText.text = "âœ… æ’­æ”¾å®Œæˆ!\n" +
                    "æ—¥æ–‡: ${sentence.text}\n" +
                    "æ„æ€: ${sentence.translation}\n" +
                    "å¯ä»¥é€‰æ‹©å…¶ä»–å¥å­ç»§ç»­æµ‹è¯•"
            
        } catch (e: Exception) {
            statusText.text = "âŒ åˆæˆå¤±è´¥:\n${e.message}"
            e.printStackTrace()
        }
    }
    
    private suspend fun playAudio(waveform: FloatArray) = withContext(Dispatchers.IO) {
        val sampleRate = 24000
        val bufferSize = AudioTrack.getMinBufferSize(
            sampleRate,
            AudioFormat.CHANNEL_OUT_MONO,
            AudioFormat.ENCODING_PCM_FLOAT
        )
        
        println("ğŸ”Š å¼€å§‹æ’­æ”¾: é‡‡æ ·ç‡=$sampleRate, ç¼“å†²=$bufferSize, æ•°æ®é•¿åº¦=${waveform.size}")
        
        audioTrack = AudioTrack.Builder()
            .setAudioAttributes(
                AudioAttributes.Builder()
                    .setUsage(AudioAttributes.USAGE_MEDIA)
                    .setContentType(AudioAttributes.CONTENT_TYPE_SPEECH)
                    .build()
            )
            .setAudioFormat(
                AudioFormat.Builder()
                    .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                    .setSampleRate(sampleRate)
                    .setChannelMask(AudioFormat.CHANNEL_OUT_MONO)
                    .build()
            )
            .setBufferSizeInBytes(bufferSize.coerceAtLeast(waveform.size * 4))
            .setTransferMode(AudioTrack.MODE_STATIC)  // ä½¿ç”¨é™æ€æ¨¡å¼
            .build()
        
        audioTrack?.apply {
            // å†™å…¥æ•°æ®
            val written = write(waveform, 0, waveform.size, AudioTrack.WRITE_BLOCKING)
            println("ğŸ’¾ å†™å…¥æ ·æœ¬æ•°: $written")
            
            // è®¾ç½®éŸ³é‡ï¼ˆæœ€å¤§ï¼‰
            setVolume(AudioTrack.getMaxVolume())
            
            // æ’­æ”¾
            play()
            println("â–¶ï¸ å¼€å§‹æ’­æ”¾")
            
            // ç­‰å¾…æ’­æ”¾å®Œæˆï¼ˆé™æ€æ¨¡å¼ä¼šè‡ªåŠ¨åœæ­¢ï¼‰
            while (playState == AudioTrack.PLAYSTATE_PLAYING) {
                Thread.sleep(100)
            }
            
            println("â¹ï¸ æ’­æ”¾å®Œæˆ")
            stop()
            release()
        }
    }
    
    override fun onDestroy() {
        super.onDestroy()
        engine.release()
        audioTrack?.release()
    }
}
