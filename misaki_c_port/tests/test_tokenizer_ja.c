/**
 * test_tokenizer_ja.c
 * 
 * æµ‹è¯•æ—¥æ–‡åˆ†è¯å™¨
 * 
 * License: MIT
 */

#include "misaki_tokenizer.h"
#include <stdio.h>
#include <string.h>
#include <assert.h>

// æµ‹è¯•ç»“æœç»Ÿè®¡
static int test_passed = 0;
static int test_failed = 0;

#define TEST_ASSERT(cond, msg) do { \
    if (!(cond)) { \
        printf("  âŒ FAIL: %s\n", msg); \
        test_failed++; \
        return; \
    } \
} while(0)

#define RUN_TEST(test_func) do { \
    printf("\nğŸ§ª Running %s...\n", #test_func); \
    test_func(); \
    test_passed++; \
} while(0)

/* ============================================================================
 * æ—¥æ–‡åˆ†è¯å™¨æµ‹è¯•
 * ========================================================================== */

void test_ja_tokenizer_create() {
    // åˆ›å»ºç®€å•çš„ Trie
    Trie *trie = misaki_trie_create();
    TEST_ASSERT(trie != NULL, "Trie åº”è¯¥åˆ›å»ºæˆåŠŸ");
    
    JaTokenizerConfig config = {
        .dict_trie = trie,
        .use_simple_model = true
    };
    
    void *tokenizer = misaki_ja_tokenizer_create(&config);
    TEST_ASSERT(tokenizer != NULL, "æ—¥æ–‡åˆ†è¯å™¨åº”è¯¥åˆ›å»ºæˆåŠŸ");
    
    misaki_ja_tokenizer_free(tokenizer);
    misaki_trie_free(trie);
    
    printf("  âœ… æ—¥æ–‡åˆ†è¯å™¨åˆ›å»ºæˆåŠŸ\n");
}

void test_ja_tokenize_hiragana() {
    Trie *trie = misaki_trie_create();
    misaki_trie_insert(trie, "ã“ã‚“ã«ã¡ã¯", 1000.0, NULL);
    
    JaTokenizerConfig config = {
        .dict_trie = trie,
        .use_simple_model = true
    };
    
    void *tokenizer = misaki_ja_tokenizer_create(&config);
    TEST_ASSERT(tokenizer != NULL, "åˆ†è¯å™¨åº”è¯¥åˆ›å»ºæˆåŠŸ");
    
    // æµ‹è¯•å¹³å‡å
    const char *text = "ã“ã‚“ã«ã¡ã¯";
    MisakiTokenList *tokens = misaki_ja_tokenize(tokenizer, text);
    TEST_ASSERT(tokens != NULL, "åˆ†è¯ç»“æœä¸åº”ä¸º NULL");
    
    int count = misaki_token_list_size(tokens);
    printf("  åˆ†è¯ç»“æœ: %d ä¸ªè¯\n", count);
    
    for (int i = 0; i < count; i++) {
        MisakiToken *token = misaki_token_list_get(tokens, i);
        printf("    [%d] '%s' (tag: %s)\n", i, token->text, token->tag ? token->tag : "NULL");
    }
    
    TEST_ASSERT(count >= 1, "è‡³å°‘åº”è¯¥æœ‰ 1 ä¸ªè¯");
    
    misaki_token_list_free(tokens);
    misaki_ja_tokenizer_free(tokenizer);
    misaki_trie_free(trie);
    
    printf("  âœ… æ—¥æ–‡å¹³å‡ååˆ†è¯æµ‹è¯•é€šè¿‡\n");
}

void test_ja_tokenize_katakana() {
    Trie *trie = misaki_trie_create();
    misaki_trie_insert(trie, "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿", 1000.0, NULL);
    
    JaTokenizerConfig config = {
        .dict_trie = trie,
        .use_simple_model = true
    };
    
    void *tokenizer = misaki_ja_tokenizer_create(&config);
    
    // æµ‹è¯•ç‰‡å‡å
    const char *text = "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿";
    MisakiTokenList *tokens = misaki_ja_tokenize(tokenizer, text);
    TEST_ASSERT(tokens != NULL, "åˆ†è¯ç»“æœä¸åº”ä¸º NULL");
    
    printf("  åˆ†è¯ç»“æœ: %d ä¸ªè¯\n", tokens->count);
    for (int i = 0; i < tokens->count; i++) {
        MisakiToken *token = misaki_token_list_get(tokens, i);
        printf("    [%d] '%s'\n", i, token->text);
    }
    
    misaki_token_list_free(tokens);
    misaki_ja_tokenizer_free(tokenizer);
    misaki_trie_free(trie);
    
    printf("  âœ… æ—¥æ–‡ç‰‡å‡ååˆ†è¯æµ‹è¯•é€šè¿‡\n");
}

void test_ja_tokenize_kanji() {
    Trie *trie = misaki_trie_create();
    misaki_trie_insert(trie, "æ—¥æœ¬èª", 1000.0, NULL);
    
    JaTokenizerConfig config = {
        .dict_trie = trie,
        .use_simple_model = true
    };
    
    void *tokenizer = misaki_ja_tokenizer_create(&config);
    
    // æµ‹è¯•æ±‰å­—
    const char *text = "æ—¥æœ¬èª";
    MisakiTokenList *tokens = misaki_ja_tokenize(tokenizer, text);
    TEST_ASSERT(tokens != NULL, "åˆ†è¯ç»“æœä¸åº”ä¸º NULL");
    
    printf("  åˆ†è¯ç»“æœ: %d ä¸ªè¯\n", tokens->count);
    for (int i = 0; i < tokens->count; i++) {
        MisakiToken *token = misaki_token_list_get(tokens, i);
        printf("    [%d] '%s'\n", i, token->text);
    }
    
    misaki_token_list_free(tokens);
    misaki_ja_tokenizer_free(tokenizer);
    misaki_trie_free(trie);
    
    printf("  âœ… æ—¥æ–‡æ±‰å­—åˆ†è¯æµ‹è¯•é€šè¿‡\n");
}

void test_ja_tokenize_mixed() {
    Trie *trie = misaki_trie_create();
    misaki_trie_insert(trie, "ç§", 1000.0, NULL);
    misaki_trie_insert(trie, "ã¯", 800.0, NULL);
    misaki_trie_insert(trie, "å­¦ç”Ÿ", 900.0, NULL);
    misaki_trie_insert(trie, "ã§ã™", 700.0, NULL);
    
    JaTokenizerConfig config = {
        .dict_trie = trie,
        .use_simple_model = true
    };
    
    void *tokenizer = misaki_ja_tokenizer_create(&config);
    
    // æµ‹è¯•æ··åˆæ–‡æœ¬
    const char *text = "ç§ã¯å­¦ç”Ÿã§ã™";
    MisakiTokenList *tokens = misaki_ja_tokenize(tokenizer, text);
    TEST_ASSERT(tokens != NULL, "åˆ†è¯ç»“æœä¸åº”ä¸º NULL");
    
    printf("  åˆ†è¯ç»“æœ: %d ä¸ªè¯\n", tokens->count);
    for (int i = 0; i < tokens->count; i++) {
        MisakiToken *token = misaki_token_list_get(tokens, i);
        printf("    [%d] '%s' (tag: %s)\n", i, token->text, token->tag ? token->tag : "NULL");
    }
    
    // åº”è¯¥åŒ…å«å‡åå’Œæ±‰å­—
    bool has_hiragana = false;
    bool has_kanji = false;
    
    for (int i = 0; i < tokens->count; i++) {
        MisakiToken *token = misaki_token_list_get(tokens, i);
        if (token->tag && strcmp(token->tag, "hiragana") == 0) has_hiragana = true;
        if (token->tag && strcmp(token->tag, "kanji") == 0) has_kanji = true;
    }
    
    misaki_token_list_free(tokens);
    misaki_ja_tokenizer_free(tokenizer);
    misaki_trie_free(trie);
    
    printf("  âœ… æ—¥æ–‡æ··åˆæ–‡æœ¬åˆ†è¯æµ‹è¯•é€šè¿‡\n");
}

void test_ja_tokenize_punctuation() {
    Trie *trie = misaki_trie_create();
    misaki_trie_insert(trie, "ã“ã‚“ã«ã¡ã¯", 1000.0, NULL);
    misaki_trie_insert(trie, "å…ƒæ°—", 900.0, NULL);
    misaki_trie_insert(trie, "ã§ã™ã‹", 800.0, NULL);
    
    JaTokenizerConfig config = {
        .dict_trie = trie,
        .use_simple_model = true
    };
    
    void *tokenizer = misaki_ja_tokenizer_create(&config);
    
    // æµ‹è¯•æ ‡ç‚¹ç¬¦å·
    const char *text = "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ";
    MisakiTokenList *tokens = misaki_ja_tokenize(tokenizer, text);
    TEST_ASSERT(tokens != NULL, "åˆ†è¯ç»“æœä¸åº”ä¸º NULL");
    
    printf("  åˆ†è¯ç»“æœ: %d ä¸ªè¯\n", tokens->count);
    for (int i = 0; i < tokens->count; i++) {
        MisakiToken *token = misaki_token_list_get(tokens, i);
        printf("    [%d] '%s' (tag: %s)\n", i, token->text, token->tag ? token->tag : "NULL");
    }
    
    misaki_token_list_free(tokens);
    misaki_ja_tokenizer_free(tokenizer);
    misaki_trie_free(trie);
    
    printf("  âœ… æ—¥æ–‡æ ‡ç‚¹ç¬¦å·æµ‹è¯•é€šè¿‡\n");
}

/* ============================================================================
 * ä¸»æµ‹è¯•å‡½æ•°
 * ========================================================================== */

int main(void) {
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    printf("  æ—¥æ–‡åˆ†è¯å™¨æµ‹è¯•\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    
    RUN_TEST(test_ja_tokenizer_create);
    RUN_TEST(test_ja_tokenize_hiragana);
    RUN_TEST(test_ja_tokenize_katakana);
    RUN_TEST(test_ja_tokenize_kanji);
    RUN_TEST(test_ja_tokenize_mixed);
    RUN_TEST(test_ja_tokenize_punctuation);
    
    // æ€»ç»“
    printf("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    printf("  æµ‹è¯•ç»“æœ:\n");
    printf("  âœ… é€šè¿‡: %d\n", test_passed);
    printf("  âŒ å¤±è´¥: %d\n", test_failed);
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    
    return test_failed > 0 ? 1 : 0;
}
