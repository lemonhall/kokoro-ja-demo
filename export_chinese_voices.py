"""
å¯¼å‡ºä¸­æ–‡è¯­éŸ³åµŒå…¥æ•°æ®ä¾› Android ä½¿ç”¨

åŸºäº export_voices_for_android.pyï¼Œä¿®æ”¹ä¸ºæ”¯æŒä¸­æ–‡è¯­éŸ³
å…³é”®æ”¹åŠ¨ï¼š
1. lang_code='z' (ä¸­æ–‡)
2. å¯¼å‡º zf_xiaoxiao ç­‰ä¸­æ–‡éŸ³è‰²
3. ä¿ç•™å®Œæ•´ 510 å¸§åµŒå…¥æ•°æ®ï¼Œæ”¯æŒåŠ¨æ€å¸§é€‰æ‹©
"""

from kokoro import KPipeline
import numpy as np
import struct
import os

# åˆå§‹åŒ–ä¸­æ–‡ Pipeline
print("åˆå§‹åŒ– Kokoro (ä¸­æ–‡æ¨¡å¼)...")
pipeline = KPipeline(lang_code='z')  # 'z' = ä¸­æ–‡

# å¯ç”¨çš„ä¸­æ–‡è¯­éŸ³åˆ—è¡¨
# æ³¨æ„ï¼šå…·ä½“å¯ç”¨éŸ³è‰²éœ€è¦æŸ¥çœ‹ kokoro æ–‡æ¡£æˆ–æµ‹è¯•
available_voices = ['zf_xiaoxiao']  # å…ˆå¯¼å‡ºä¸»è¦çš„ä¸­æ–‡å¥³å£°

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs('app/src/main/assets/voices', exist_ok=True)
os.makedirs('models/chinese', exist_ok=True)

print("\nå¯¼å‡ºä¸­æ–‡è¯­éŸ³åµŒå…¥æ•°æ®...")
print("=" * 60)

for voice_name in available_voices:
    try:
        # åŠ è½½è¯­éŸ³åµŒå…¥
        print(f"\nå¤„ç†ä¸­æ–‡è¯­éŸ³: {voice_name}")
        voices_tensor = pipeline.load_voice(voice_name)
        print(f"  ğŸ“Š å¼ é‡å½¢çŠ¶: {voices_tensor.shape}")
        
        # éªŒè¯å½¢çŠ¶æ˜¯å¦ç¬¦åˆé¢„æœŸ [510, 1, 256]
        expected_shape = (510, 1, 256)
        if voices_tensor.shape != expected_shape:
            print(f"  âš ï¸  è­¦å‘Š: å½¢çŠ¶ä¸åŒ¹é…! é¢„æœŸ {expected_shape}, å®é™… {voices_tensor.shape}")
        
        # è½¬æ¢ä¸º numpy
        voices_data = voices_tensor.numpy()
        
        # 1. ä¿å­˜ä¸º .npy æ ¼å¼ï¼ˆç”¨äº Python æµ‹è¯•å’ŒéªŒè¯ï¼‰
        npy_file = f'models/chinese/{voice_name}.npy'
        np.save(npy_file, voices_data)
        npy_size = os.path.getsize(npy_file) / 1024
        print(f"  âœ… NumPy æ ¼å¼: {npy_file} ({npy_size:.2f} KB)")
        
        # 2. ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ ¼å¼ï¼ˆä¾› Android ä½¿ç”¨ï¼‰
        # å…³é”®ï¼šä¿å­˜å®Œæ•´ 510 å¸§åµŒå…¥ï¼Œæ”¯æŒåŠ¨æ€å¸§é€‰æ‹©ï¼
        all_embeddings = voices_data[:, 0, :].astype(np.float32)  # [510, 256]
        
        bin_file = f'app/src/main/assets/voices/{voice_name}.bin'
        with open(bin_file, 'wb') as f:
            # å†™å…¥å…ƒæ•°æ®
            f.write(struct.pack('i', 256))  # embedding_dim
            f.write(struct.pack('i', 510))  # num_frames
            
            # å†™å…¥æ‰€æœ‰ 510 å¸§çš„åµŒå…¥æ•°æ®
            f.write(all_embeddings.tobytes())
        
        bin_size = os.path.getsize(bin_file) / 1024
        print(f"  âœ… äºŒè¿›åˆ¶æ ¼å¼: {bin_file} ({bin_size:.2f} KB)")
        print(f"     åŒ…å« {all_embeddings.shape[0]} å¸§åµŒå…¥æ•°æ® (æ”¯æŒåŠ¨æ€å¸§é€‰æ‹©)")
        
        # 3. æ•°æ®éªŒè¯
        print(f"  ğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
        print(f"     å€¼åŸŸ: [{all_embeddings.min():.4f}, {all_embeddings.max():.4f}]")
        print(f"     å‡å€¼: {all_embeddings.mean():.4f}")
        print(f"     æ ‡å‡†å·®: {all_embeddings.std():.4f}")
        
        # 4. éªŒè¯ä¸åŒå¸§ä¹‹é—´çš„å·®å¼‚
        frame_0 = all_embeddings[0, :]
        frame_10 = all_embeddings[10, :]
        frame_50 = all_embeddings[50, :]
        
        diff_0_10 = np.mean(np.abs(frame_0 - frame_10))
        diff_0_50 = np.mean(np.abs(frame_0 - frame_50))
        
        print(f"  ğŸ“Š å¸§é—´å·®å¼‚ (éªŒè¯éŸµå¾‹å˜åŒ–):")
        print(f"     Frame 0 vs Frame 10: {diff_0_10:.4f}")
        print(f"     Frame 0 vs Frame 50: {diff_0_50:.4f}")
        print(f"     âœ… é•¿å¥éŸµå¾‹å·®å¼‚æ˜æ˜¾: {diff_0_50 > diff_0_10}")
        
    except Exception as e:
        print(f"  âŒ å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

# æ›´æ–° VoiceEmbeddingLoader.kt æ·»åŠ ä¸­æ–‡éŸ³è‰²
kotlin_update = """
// åœ¨ VoiceEmbeddingLoader.kt ä¸­æ·»åŠ ä¸­æ–‡éŸ³è‰²æ”¯æŒ

/**
 * è·å–å¯ç”¨çš„è¯­éŸ³åˆ—è¡¨
 */
object AvailableVoices {
    // æ—¥æ–‡éŸ³è‰²
    val japanese = listOf(
        "jf_nezumi",  // å¥³å£°
        "jf_hanako",  // å¥³å£°
        "jm_shinji"   // ç”·å£°
    )
    
    // ä¸­æ–‡éŸ³è‰²
    val chinese = listOf(
        "zf_xiaoxiao"  // å¥³å£°
    )
    
    // æ‰€æœ‰éŸ³è‰²
    val all = japanese + chinese
}

/**
 * éŸ³è‰²è¯­è¨€æ˜ å°„
 */
fun getLanguage(voiceName: String): String {
    return when (voiceName) {
        in AvailableVoices.japanese -> "ja"
        in AvailableVoices.chinese -> "zh"
        else -> throw IllegalArgumentException("æœªçŸ¥éŸ³è‰²: $voiceName")
    }
}
"""

print("\n" + "=" * 60)
print("ğŸ“ Kotlin ä»£ç æ›´æ–°å»ºè®®")
print("=" * 60)
print(kotlin_update)

print("\n" + "=" * 60)
print("âœ… å¯¼å‡ºå®Œæˆ!")
print("=" * 60)

# è¾“å‡ºæ–‡ä»¶åˆ—è¡¨
print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")

print("\n  Python/æµ‹è¯•ç”¨ (models/chinese/):")
for voice in available_voices:
    npy_file = f'models/chinese/{voice}.npy'
    if os.path.exists(npy_file):
        size = os.path.getsize(npy_file) / 1024
        print(f"    âœ… {voice}.npy ({size:.2f} KB)")

print("\n  Android ä½¿ç”¨ (app/src/main/assets/voices/):")
for voice in available_voices:
    bin_file = f'app/src/main/assets/voices/{voice}.bin'
    if os.path.exists(bin_file):
        size = os.path.getsize(bin_file) / 1024
        print(f"    âœ… {voice}.bin ({size:.2f} KB)")

# æµ‹è¯•éªŒè¯
print("\n" + "=" * 60)
print("ğŸ§ª Python ç«¯éªŒè¯æµ‹è¯•")
print("=" * 60)

try:
    test_text = "ä¸­æ–‡æµ‹è¯•ï¼Œé•¿å¥æœ—è¯»"
    
    print(f"\næµ‹è¯•æ–‡æœ¬: {test_text}")
    
    # ä½¿ç”¨ Pipeline ç”ŸæˆéŸ³é¢‘
    result = list(pipeline(test_text, voice='zf_xiaoxiao', speed=1))
    
    if result:
        gs, ps, audio = result[0]
        phoneme_length = len(ps)
        audio_duration = len(audio) / 24000.0
        
        print(f"  æ–‡æœ¬: {gs}")
        print(f"  éŸ³ç´ : {ps}")
        print(f"  éŸ³ç´ é•¿åº¦: {phoneme_length}")
        print(f"  éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f} ç§’")
        print(f"  åº”é€‰æ‹©å¸§: {phoneme_length - 1}")
        
        # éªŒè¯åŠ¨æ€å¸§é€‰æ‹©
        voices_tensor = pipeline.load_voice('zf_xiaoxiao')
        frame_index = phoneme_length - 1
        selected_embedding = voices_tensor[frame_index, 0, :]
        
        print(f"  âœ… åŠ¨æ€å¸§é€‰æ‹©éªŒè¯:")
        print(f"     é€‰æ‹©çš„å¸§: {frame_index} (å…± {voices_tensor.shape[0]} å¸§)")
        print(f"     åµŒå…¥ç»´åº¦: {selected_embedding.shape}")
        
        # ä¿å­˜æµ‹è¯•éŸ³é¢‘
        import soundfile as sf
        test_audio_file = 'models/chinese/test_xiaoxiao.wav'
        sf.write(test_audio_file, audio, 24000)
        print(f"\n  ğŸ’¾ æµ‹è¯•éŸ³é¢‘å·²ä¿å­˜: {test_audio_file}")
        
    else:
        print("  âš ï¸  æœªç”ŸæˆéŸ³é¢‘")
        
except Exception as e:
    print(f"\n  âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# ä½¿ç”¨è¯´æ˜
print("\n" + "=" * 60)
print("ğŸ“– Android ç«¯ä½¿ç”¨è¯´æ˜")
print("=" * 60)

print("""
1. åŠ è½½ä¸­æ–‡è¯­éŸ³åµŒå…¥:
   val voiceEmbedding = VoiceEmbeddingLoader.load(context, "zf_xiaoxiao")

2. æ ¹æ®éŸ³ç´ é•¿åº¦åŠ¨æ€é€‰æ‹©å¸§:
   val phonemeLength = inputIds.size - 2  // å»æ‰ BOS å’Œ EOS
   val selectedEmbedding = voiceEmbedding.getFrameByPhonemeLength(phonemeLength)

3. å®Œæ•´æ¨ç†æµç¨‹:
   // ä¸­æ–‡æ–‡æœ¬ â†’ æ‹¼éŸ³ â†’ IPA éŸ³ç´ 
   val phonemes = chineseG2P.textToPhonemes("ä¸­æ–‡æµ‹è¯•")
   
   // éŸ³ç´  â†’ input_ids
   val inputIds = KokoroVocabFull.phonemesToIds(phonemes)
   
   // åŠ è½½ä¸­æ–‡è¯­éŸ³åµŒå…¥å¹¶åŠ¨æ€é€‰æ‹©å¸§
   val voiceEmbedding = VoiceEmbeddingLoader.load(context, "zf_xiaoxiao")
   val phonemeLength = inputIds.size - 2
   val embedding = voiceEmbedding.getFrameByPhonemeLength(phonemeLength)
   
   // TTS æ¨ç†
   val waveform = engine.synthesize(inputIds, embedding, speed = 1.0)

âš ï¸ æ³¨æ„äº‹é¡¹:
   - å¿…é¡»ä¿ç•™å®Œæ•´ 510 å¸§æ•°æ®
   - å¿…é¡»æ ¹æ®éŸ³ç´ é•¿åº¦åŠ¨æ€é€‰æ‹©å¸§
   - çŸ­å¥ç”¨ç¬¬ä¸€å¸§ï¼Œé•¿å¥ç”¨å¯¹åº”å¸§
   - è¿™æ˜¯éŸ³è´¨çš„å…³é”®ï¼
""")

print("\nğŸ‰ å…¨éƒ¨å®Œæˆ!")
print("\nä¸‹ä¸€æ­¥:")
print("  1. âœ… ä¸­æ–‡è¯­éŸ³åµŒå…¥å·²å¯¼å‡º")
print("  2. â³ åˆ›å»º ChinesePinyinToIPA.kt")
print("  3. â³ é›†æˆ TinyPinyin åº“")
print("  4. â³ å®ç° ChineseG2PSystem.kt")
print("  5. â³ ä¿®æ”¹ MainActivity æ”¯æŒåŒè¯­è¨€")
print()
