"""
æœ€ç»ˆæ­£ç¡®çš„ ONNX æµ‹è¯•
å®Œå…¨æ¨¡æ‹Ÿ PyTorch pipeline çš„æµç¨‹

ç”¨æ³•:
  uv run python test_onnx.py                          # é»˜è®¤æµ‹è¯• kokoro_latest.onnx
  uv run python test_onnx.py kokoro_latest_int8.onnx  # æµ‹è¯• INT8 é‡åŒ–ç‰ˆæœ¬
  uv run python test_onnx.py --text "ä½ å¥½" --voice jf_nezumi
"""

import onnxruntime as ort
import numpy as np
import soundfile as sf
from kokoro import KPipeline
import torch
import sys
import argparse
import os

def main():
    # å‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='æµ‹è¯• Kokoro ONNX æ¨¡å‹')
    parser.add_argument(
        'model',
        nargs='?',
        default='kokoro_latest.onnx',
        help='ONNX æ¨¡å‹è·¯å¾„ (é»˜è®¤: kokoro_latest.onnx)'
    )
    parser.add_argument(
        '--text',
        default='ã“ã‚“ã«ã¡ã¯',
        help='æµ‹è¯•æ–‡æœ¬ (é»˜è®¤: ã“ã‚“ã«ã¡ã¯)'
    )
    parser.add_argument(
        '--voice',
        default='jf_nezumi',
        help='è¯­éŸ³åç§° (é»˜è®¤: jf_nezumi)'
    )
    args = parser.parse_args()
    
    onnx_path = args.model
    text = args.text
    voice_name = args.voice
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(onnx_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {onnx_path}")
        print(f"\nè¯·å…ˆå¯¼å‡º ONNX æ¨¡å‹:")
        print(f"  uv run python export_onnx.py")
        sys.exit(1)
    
    model_size = os.path.getsize(onnx_path) / (1024 * 1024)
    print("="*70)
    print(f"æµ‹è¯• ONNX æ¨¡å‹: {onnx_path}")
    print(f"æ¨¡å‹å¤§å°: {model_size:.2f} MB")
    print(f"æ–‡æœ¬: {text}")
    print(f"è¯­éŸ³: {voice_name}")
    print("="*70)

    # åˆå§‹åŒ–
    print("\nåˆå§‹åŒ– Kokoro...")
    pipeline = KPipeline(lang_code='j')

    # 1. ä½¿ç”¨ pipeline ç”Ÿæˆå‚è€ƒéŸ³é¢‘
    print(f"\n1ï¸âƒ£  ä½¿ç”¨ PyTorch Pipeline ç”Ÿæˆå‚è€ƒéŸ³é¢‘...")
    print(f"   æ–‡æœ¬: {text}")
    for i, (gs, ps, audio) in enumerate(pipeline(text, voice=voice_name, speed=1, split_pattern=r'\n+')):
        if i == 0:
            sf.write('reference_pytorch.wav', audio, 24000)
            print(f"   Graphemes: {gs}")
            print(f"   Phonemes: {ps}")
            print(f"   âœ… ä¿å­˜: reference_pytorch.wav ({len(audio)/24000:.2f}ç§’)")
            phoneme_string = ps
            break

    # 2. æ‰‹åŠ¨è½¬æ¢éŸ³ç´ ä¸º input_idsï¼ˆæ¨¡æ‹Ÿæ¨¡å‹çš„ forward æ–¹æ³•ï¼‰
    print(f"\n2ï¸âƒ£  è½¬æ¢éŸ³ç´ ä¸º input_ids...")
    vocab = pipeline.model.vocab
    print(f"   éŸ³ç´ å­—ç¬¦ä¸²: '{phoneme_string}'")
    print(f"   å­—ç¬¦: {[c for c in phoneme_string]}")

    input_ids = list(filter(lambda i: i is not None, map(lambda p: vocab.get(p), phoneme_string)))
    print(f"   input_ids (ä¸å«BOS/EOS): {input_ids}")
    print(f"   é•¿åº¦: {len(input_ids)}")

    # åŠ ä¸Š BOS å’Œ EOS
    input_ids_with_special = [0, *input_ids, 0]
    print(f"   input_ids (å«BOS/EOS): {input_ids_with_special}")

    # 3. åŠ è½½è¯­éŸ³åµŒå…¥
    print(f"\n3ï¸âƒ£  åŠ è½½è¯­éŸ³åµŒå…¥...")
    voices_tensor = pipeline.load_voice(voice_name)  # [510, 1, 256]
    ref_s = voices_tensor[0, 0, :].unsqueeze(0)  # [1, 256]
    print(f"   è¯­éŸ³åµŒå…¥å½¢çŠ¶: {ref_s.shape}")

    # 4. ONNX æ¨ç†
    print(f"\n4ï¸âƒ£  ONNX æ¨ç†...")
    print(f"   åŠ è½½æ¨¡å‹: {onnx_path}")
    
    try:
        session = ort.InferenceSession(onnx_path)
    except Exception as e:
        print(f"\nâŒ åŠ è½½ ONNX æ¨¡å‹å¤±è´¥: {e}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ ConvInteger é—®é¢˜
        if 'ConvInteger' in str(e):
            print(f"\nğŸ’¡ æ£€æµ‹åˆ° ConvInteger ä¸æ”¯æŒçš„é—®é¢˜")
            print(f"\nè¿™é€šå¸¸å‘ç”Ÿåœ¨ INT8 é‡åŒ–æ¨¡å‹ä¸Šã€‚è§£å†³æ–¹æ¡ˆ:")
            print(f"  1. ä½¿ç”¨ FP32 ç‰ˆæœ¬: uv run python test_onnx.py kokoro_latest.onnx")
            print(f"  2. ä½¿ç”¨ FP16 ç‰ˆæœ¬: uv run python convert_fp16.py && uv run python test_onnx.py kokoro_latest_fp16.onnx")
            print(f"  3. å‡çº§ ONNX Runtime: uv add onnxruntime --upgrade")
            print(f"\næ³¨æ„: INT8 é‡åŒ–åœ¨ç§»åŠ¨ç«¯ï¼ˆNNAPI/CoreMLï¼‰ä¸Šæ‰èƒ½å……åˆ†å‘æŒ¥ä¼˜åŠ¿")
        
        sys.exit(1)

    inputs = {
        'input_ids': np.array([input_ids_with_special], dtype=np.int64),
        'ref_s': ref_s.numpy(),
        'speed': np.array(1.0, dtype=np.float64)
    }

    outputs = session.run(None, inputs)
    onnx_waveform = outputs[0]

    print(f"   è¾“å‡ºå½¢çŠ¶: {onnx_waveform.shape}")
    print(f"   å³°å€¼: {np.max(np.abs(onnx_waveform)):.3f}")

    # å½’ä¸€åŒ–
    if np.max(np.abs(onnx_waveform)) > 1.0:
        onnx_waveform = onnx_waveform / np.max(np.abs(onnx_waveform)) * 0.95

    sf.write('onnx_final_output.wav', onnx_waveform, 24000)
    print(f"   âœ… ä¿å­˜: onnx_final_output.wav ({len(onnx_waveform)/24000:.2f}ç§’)")

    # 5. PyTorch forward_with_tokens å¯¹æ¯”
    print(f"\n5ï¸âƒ£  PyTorch forward_with_tokens å¯¹æ¯”...")
    input_ids_tensor = torch.tensor([input_ids_with_special], dtype=torch.long)
    with torch.no_grad():
        pt_waveform, pt_duration = pipeline.model.forward_with_tokens(input_ids_tensor, ref_s, speed=1.0)
    pt_waveform = pt_waveform.numpy()

    sf.write('pytorch_forward_tokens.wav', pt_waveform, 24000)
    print(f"   è¾“å‡ºå½¢çŠ¶: {pt_waveform.shape}")
    print(f"   å³°å€¼: {np.max(np.abs(pt_waveform)):.3f}")
    print(f"   âœ… ä¿å­˜: pytorch_forward_tokens.wav ({len(pt_waveform)/24000:.2f}ç§’)")

    # 6. å¯¹æ¯”å·®å¼‚
    print(f"\n6ï¸âƒ£  æ•°å€¼å¯¹æ¯”...")
    min_len = min(len(onnx_waveform), len(pt_waveform))
    diff = np.abs(onnx_waveform[:min_len] - pt_waveform[:min_len])
    print(f"   æœ€å¤§å·®å¼‚: {np.max(diff):.6f}")
    print(f"   å¹³å‡å·®å¼‚: {np.mean(diff):.6f}")
    print(f"   ç›¸å¯¹è¯¯å·®: {np.mean(diff)/np.mean(np.abs(pt_waveform[:min_len]))*100:.2f}%")

    if np.max(diff) < 0.01:
        print(f"   âœ… ONNX å’Œ PyTorch è¾“å‡ºåŸºæœ¬ä¸€è‡´!")
    else:
        print(f"   âš ï¸  å­˜åœ¨å·®å¼‚ï¼Œä½†å¯èƒ½æ˜¯æ­£å¸¸çš„æµ®ç‚¹æ•°è¯¯å·®")

    print(f"\n{'='*70}")
    print(f"âœ… æµ‹è¯•å®Œæˆ! è¯·æ’­æ”¾ä»¥ä¸‹æ–‡ä»¶éªŒè¯:")
    print(f"   - reference_pytorch.wav (Pipeline å®Œæ•´æµç¨‹)")
    print(f"   - pytorch_forward_tokens.wav (PyTorch forward_with_tokens)")
    print(f"   - onnx_final_output.wav (ONNX æ¨ç†)")
    print(f"{'='*70}")

if __name__ == "__main__":
    main()
