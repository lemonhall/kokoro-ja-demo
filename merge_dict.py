#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆå¹¶ä¸­æ–‡è¯å…¸ï¼šdict_full.txt + proper_nouns.txt

ç­–ç•¥ï¼š
1. åŠ è½½å¤§è¯å…¸ dict_full.txt
2. åŠ è½½ä¸“æœ‰åè¯ proper_nouns.txt
3. åˆå¹¶å»é‡ï¼ˆä¸“æœ‰åè¯ä¼˜å…ˆï¼Œå› ä¸ºè¯é¢‘æ›´é«˜ï¼‰
4. è¾“å‡ºåˆ° dict_merged.txt
"""

from pathlib import Path

def load_dict(file_path):
    """åŠ è½½è¯å…¸æ–‡ä»¶"""
    words = {}
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            parts = line.strip().split('\t')
            if len(parts) >= 2:
                word = parts[0]
                freq = int(parts[1])
                words[word] = freq
    return words

def main():
    print("ğŸš€ å¼€å§‹åˆå¹¶è¯å…¸...\n")
    
    data_dir = Path(__file__).parent / "misaki_c_port" / "extracted_data" / "zh"
    
    # 1. åŠ è½½å¤§è¯å…¸
    dict_full_path = data_dir / "dict_full.txt"
    print(f"ğŸ“– åŠ è½½å¤§è¯å…¸: {dict_full_path}")
    dict_full = load_dict(dict_full_path)
    print(f"   âœ… {len(dict_full)} ä¸ªè¯æ±‡")
    
    # 2. åŠ è½½ä¸“æœ‰åè¯
    proper_nouns_path = data_dir / "proper_nouns.txt"
    print(f"ğŸ“– åŠ è½½ä¸“æœ‰åè¯: {proper_nouns_path}")
    proper_nouns = load_dict(proper_nouns_path)
    print(f"   âœ… {len(proper_nouns)} ä¸ªä¸“æœ‰åè¯")
    
    # 3. åˆå¹¶ï¼ˆä¸“æœ‰åè¯ä¼˜å…ˆï¼Œè¦†ç›–åŸè¯å…¸ä¸­çš„ä½é¢‘è¯ï¼‰
    print("\nğŸ”„ åˆå¹¶è¯å…¸...")
    merged = dict_full.copy()
    
    new_count = 0
    updated_count = 0
    
    for word, freq in proper_nouns.items():
        if word in merged:
            if freq > merged[word]:
                merged[word] = freq
                updated_count += 1
        else:
            merged[word] = freq
            new_count += 1
    
    print(f"   âœ… æ–°å¢: {new_count} ä¸ªè¯æ±‡")
    print(f"   âœ… æ›´æ–°: {updated_count} ä¸ªè¯æ±‡ï¼ˆæå‡è¯é¢‘ï¼‰")
    print(f"   âœ… æ€»è®¡: {len(merged)} ä¸ªè¯æ±‡")
    
    # 4. æŒ‰è¯é¢‘æ’åº
    print("\nğŸ“Š æŒ‰è¯é¢‘æ’åº...")
    sorted_words = sorted(merged.items(), key=lambda x: x[1], reverse=True)
    
    # 5. è¾“å‡ºåˆ°æ–‡ä»¶
    output_file = data_dir / "dict_merged.txt"
    print(f"ğŸ’¾ ä¿å­˜åˆå¹¶è¯å…¸: {output_file}")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for word, freq in sorted_words:
            f.write(f"{word}\t{freq}\n")
    
    print(f"\nâœ¨ å®Œæˆï¼åˆå¹¶è¯å…¸ï¼š{len(merged)} ä¸ªè¯æ±‡")
    
    # æ˜¾ç¤ºå‰10ä¸ªé«˜é¢‘è¯
    print("\nğŸ” å‰10ä¸ªé«˜é¢‘è¯:")
    for i, (word, freq) in enumerate(sorted_words[:10], 1):
        print(f"   {i}. {word} ({freq})")

if __name__ == "__main__":
    main()
