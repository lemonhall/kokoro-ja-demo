#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
生成专有名词词典（中国高校、城市、机构）

输出格式：词<Tab>词频
词频统一设为较高值，避免被拆分
"""

from pathlib import Path

def generate_universities():
    """生成中国高校列表（部分示例，可扩展）"""
    universities = [
        # 985高校
        "北京大学", "清华大学", "中国人民大学", "北京师范大学", "北京理工大学",
        "北京航空航天大学", "中国农业大学", "中央民族大学",
        "复旦大学", "上海交通大学", "同济大学", "华东师范大学",
        "南京大学", "东南大学",
        "浙江大学",
        "中国科学技术大学",
        "厦门大学",
        "山东大学", "中国海洋大学",
        "武汉大学", "华中科技大学",
        "湖南大学", "中南大学",
        "中山大学", "华南理工大学",
        "四川大学", "电子科技大学",
        "重庆大学",
        "西安交通大学", "西北工业大学", "西北农林科技大学",
        "兰州大学",
        "东北大学", "大连理工大学",
        "吉林大学",
        "哈尔滨工业大学",
        "天津大学", "南开大学",
        
        # 211高校（部分）
        "北京交通大学", "北京科技大学", "北京化工大学", "北京邮电大学",
        "北京林业大学", "北京中医药大学", "北京外国语大学", "中国传媒大学",
        "中央财经大学", "对外经济贸易大学", "华北电力大学", "中国政法大学",
        "上海外国语大学", "上海财经大学", "华东理工大学", "东华大学",
        "南京航空航天大学", "南京理工大学", "河海大学", "南京农业大学",
        "中国药科大学", "南京师范大学",
        "苏州大学",
        "合肥工业大学",
        "武汉理工大学", "华中师范大学", "华中农业大学", "中南财经政法大学",
        "湖南师范大学",
        "暨南大学", "华南师范大学",
        "广西大学",
        "西南大学", "西南交通大学", "西南财经大学",
        "云南大学",
        "西北大学", "陕西师范大学", "长安大学",
        "郑州大学",
        "安徽大学",
        "南昌大学",
        "辽宁大学",
        "东北师范大学",
        "大连海事大学",
        "黑龙江大学",
        "哈尔滨工程大学",
        "内蒙古大学",
        "贵州大学",
        "海南大学",
        "石河子大学",
        "宁夏大学",
        "青海大学",
        "西藏大学",
        "新疆大学",
        
        # 其他知名高校
        "北京工业大学", "首都师范大学", "首都医科大学",
        "上海大学", "深圳大学",
        "南方科技大学", "香港中文大学深圳",
        "中国美术学院", "中央美术学院", "中央音乐学院",
        "北京体育大学", "上海体育学院",
        "外交学院", "国际关系学院",
        "中国人民公安大学", "中国刑事警察学院",
        
        # 学院（常见）
        "北京电影学院", "中央戏剧学院", "上海戏剧学院",
        "北京舞蹈学院", "解放军艺术学院",
        "外交学院", "国际关系学院",
    ]
    
    # 词频设为 50000（高于一般词汇，避免被拆分）
    return [(name, 50000) for name in universities]

def generate_cities():
    """生成中国城市列表"""
    cities = [
        # 直辖市
        "北京市", "上海市", "天津市", "重庆市",
        "北京", "上海", "天津", "重庆",
        
        # 省会城市
        "石家庄市", "太原市", "呼和浩特市", "沈阳市", "长春市", "哈尔滨市",
        "南京市", "杭州市", "合肥市", "福州市", "南昌市", "济南市",
        "郑州市", "武汉市", "长沙市", "广州市", "南宁市", "海口市",
        "成都市", "贵阳市", "昆明市", "拉萨市", "西安市", "兰州市",
        "西宁市", "银川市", "乌鲁木齐市",
        
        "石家庄", "太原", "呼和浩特", "沈阳", "长春", "哈尔滨",
        "南京", "杭州", "合肥", "福州", "南昌", "济南",
        "郑州", "武汉", "长沙", "广州", "南宁", "海口",
        "成都", "贵阳", "昆明", "拉萨", "西安", "兰州",
        "西宁", "银川", "乌鲁木齐",
        
        # 计划单列市
        "深圳市", "大连市", "青岛市", "宁波市", "厦门市",
        "深圳", "大连", "青岛", "宁波", "厦门",
        
        # 其他重要城市
        "苏州市", "无锡市", "常州市", "南通市", "徐州市", "扬州市",
        "温州市", "绍兴市", "嘉兴市", "湖州市", "金华市", "台州市",
        "佛山市", "东莞市", "中山市", "珠海市", "惠州市", "江门市",
        "唐山市", "保定市", "秦皇岛市", "邯郸市",
        "洛阳市", "开封市", "新乡市",
        "烟台市", "潍坊市", "淄博市", "威海市",
        "长沙市", "株洲市", "湘潭市", "岳阳市",
        "襄阳市", "宜昌市", "荆州市",
        "绵阳市", "德阳市", "乐山市",
        "包头市", "鄂尔多斯市",
        "赣州市", "九江市",
        "泉州市", "漳州市", "莆田市",
        "芜湖市", "蚌埠市",
        "南阳市", "安阳市",
        "榆林市", "宝鸡市", "咸阳市",
        "兰州市", "天水市",
        "银川市", "石嘴山市",
        
        "苏州", "无锡", "常州", "南通", "徐州", "扬州",
        "温州", "绍兴", "嘉兴", "湖州", "金华", "台州",
        "佛山", "东莞", "中山", "珠海", "惠州", "江门",
        "唐山", "保定", "秦皇岛", "邯郸",
        "洛阳", "开封", "新乡",
        "烟台", "潍坊", "淄博", "威海",
        "株洲", "湘潭", "岳阳",
        "襄阳", "宜昌", "荆州",
        "绵阳", "德阳", "乐山",
        "包头", "鄂尔多斯",
        "赣州", "九江",
        "泉州", "漳州", "莆田",
        "芜湖", "蚌埠",
        "南阳", "安阳",
        "榆林", "宝鸡", "咸阳",
        "天水",
        "石嘴山",
        
        # 特别行政区
        "香港", "澳门", "台北", "高雄",
    ]
    
    return [(name, 60000) for name in cities]

def generate_institutions():
    """生成常见机构名称"""
    institutions = [
        # 政府机构
        "国务院", "全国人民代表大会", "中国人民政治协商会议",
        "最高人民法院", "最高人民检察院",
        "外交部", "国防部", "发展改革委", "教育部", "科技部",
        "工业和信息化部", "公安部", "民政部", "司法部",
        "财政部", "人力资源社会保障部", "自然资源部", "生态环境部",
        "住房城乡建设部", "交通运输部", "水利部", "农业农村部",
        "商务部", "文化和旅游部", "卫生健康委", "退役军人事务部",
        "应急管理部", "中国人民银行", "审计署",
        
        # 企业
        "中国石油", "中国石化", "国家电网", "中国移动", "中国联通", "中国电信",
        "中国建筑", "中国中车", "中国航天", "中国航空",
        "中国银行", "工商银行", "建设银行", "农业银行", "交通银行",
        "中国平安", "中国人寿", "太平洋保险",
        "阿里巴巴", "腾讯", "百度", "京东", "字节跳动",
        "华为", "小米", "比亚迪", "格力", "美的", "海尔",
        "万科", "恒大", "碧桂园", "保利",
        
        # 学术机构
        "中国科学院", "中国工程院", "中国社会科学院",
        "国家自然科学基金委员会", "科学技术部",
        
        # 媒体
        "人民日报", "新华社", "中央电视台", "中央人民广播电台",
        "光明日报", "经济日报", "科技日报",
        
        # 医疗机构（知名医院）
        "北京协和医院", "北京同仁医院", "北京天坛医院", "中日友好医院",
        "上海交通大学医学院附属瑞金医院", "复旦大学附属中山医院",
        "华西医院", "湘雅医院", "齐鲁医院",
        
        # 文化场所
        "故宫博物院", "中国国家博物馆", "国家大剧院",
        "人民大会堂", "天安门广场",
        "长城", "颐和园", "圆明园", "天坛", "地坛",
        "西湖", "黄山", "泰山", "华山", "峨眉山",
    ]
    
    return [(name, 55000) for name in institutions]

def generate_compound_words():
    """生成容易被错误拆分的复合词"""
    compounds = [
        # 科技术语
        "人工智能", "机器学习", "深度学习", "神经网络", "自然语言处理",
        "计算机科学", "信息技术", "互联网", "物联网", "云计算", "大数据",
        "区块链", "虚拟现实", "增强现实", "量子计算",
        
        # 学科名称
        "物理学", "化学", "生物学", "数学", "计算机科学",
        "经济学", "管理学", "法学", "教育学", "文学",
        "历史学", "哲学", "心理学", "社会学",
        
        # 学位学历
        "博士研究生", "硕士研究生", "本科生", "专科生",
        "博士学位", "硕士学位", "学士学位",
        
        # 时间概念
        "春节", "清明节", "端午节", "中秋节", "国庆节",
        "元旦", "劳动节", "儿童节", "教师节",
        
        # 其他
        "中华人民共和国", "社会主义核心价值观",
        "改革开放", "一带一路", "粤港澳大湾区",
        "长江三角洲", "京津冀", "成渝地区",
    ]
    
    return [(name, 45000) for name in compounds]

def main():
    print("🚀 开始生成专有名词词典...\n")
    
    # 收集所有词汇
    all_words = []
    
    print("📚 生成高校名单...")
    universities = generate_universities()
    all_words.extend(universities)
    print(f"   ✅ {len(universities)} 所高校")
    
    print("🌏 生成城市列表...")
    cities = generate_cities()
    all_words.extend(cities)
    print(f"   ✅ {len(cities)} 个城市")
    
    print("🏢 生成机构名称...")
    institutions = generate_institutions()
    all_words.extend(institutions)
    print(f"   ✅ {len(institutions)} 个机构")
    
    print("📖 生成复合词...")
    compounds = generate_compound_words()
    all_words.extend(compounds)
    print(f"   ✅ {len(compounds)} 个复合词")
    
    # 去重（保留第一次出现的词频）
    seen = set()
    unique_words = []
    for word, freq in all_words:
        if word not in seen:
            seen.add(word)
            unique_words.append((word, freq))
    
    print(f"\n📊 去重后：{len(unique_words)} 个专有名词")
    
    # 输出到文件
    output_dir = Path(__file__).parent / "misaki_c_port" / "extracted_data" / "zh"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_file = output_dir / "proper_nouns.txt"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for word, freq in unique_words:
            f.write(f"{word}\t{freq}\n")
    
    print(f"💾 专有名词词典已保存: {output_file}")
    
    # 统计信息
    print("\n📊 统计信息:")
    print(f"  - 高校: {len(universities)}")
    print(f"  - 城市: {len(cities)}")
    print(f"  - 机构: {len(institutions)}")
    print(f"  - 复合词: {len(compounds)}")
    print(f"  - 总计: {len(unique_words)}")
    
    print("\n✨ 完成！")

if __name__ == "__main__":
    main()
